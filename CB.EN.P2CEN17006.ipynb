{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer - 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import hashing, tslib\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.tslibs.offsets as liboffsets\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as libalgos, ops as libops\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs.interval import (\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/internals.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import internals as libinternals\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/sparse/array.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.sparse as splib\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.window as _window\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, reduction,\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.parsers as parsers\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib, writers as libwriters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5161 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 433s 87s/step - loss: 1.1757 - acc: 0.5187 - val_loss: 0.6886 - val_acc: 0.5333\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5760100   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,779,593\n",
      "Trainable params: 5,779,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = 'relu'))\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 100, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (128, 128),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)\n",
    "print(classifier.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/test_set/cats/cat.4005.jpg', target_size = (128, 128))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a file name with dir path : dataset/test_set/cats/cat.4005.jpg\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(raw_input('Enter a file name with dir path : '), target_size = (128, 128))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer - 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: training accuracy 0.08\n",
      "Step   100: training accuracy 0.26\n",
      "Step   200: training accuracy 0.27\n",
      "Step   300: training accuracy 0.39\n",
      "Step   400: training accuracy 0.22\n",
      "Step   500: training accuracy 0.37\n",
      "Step   600: training accuracy 0.28\n",
      "Step   700: training accuracy 0.26\n",
      "Step   800: training accuracy 0.29\n",
      "Step   900: training accuracy 0.24\n",
      "Test accuracy 0.2888\n",
      "Total time:  9.38s\n"
     ]
    }
   ],
   "source": [
    "'''Softmax-Classifier for CIFAR-10'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import data_helpers\n",
    "\n",
    "beginTime = time.time()\n",
    "\n",
    "# Parameter definitions\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "max_steps = 1000\n",
    "\n",
    "# Uncommenting this line removes randomness\n",
    "# You'll get exactly the same result on each run\n",
    "# np.random.seed(1)\n",
    "\n",
    "# Prepare data\n",
    "data_sets = data_helpers.load_data()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Prepare the TensorFlow graph\n",
    "# (We're only defining the graph here, no actual calculations taking place)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define input placeholders\n",
    "images_placeholder = tf.placeholder(tf.float32, shape=[None, 3072])\n",
    "labels_placeholder = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "# Define variables (these are the values we want to optimize)\n",
    "weights = tf.Variable(tf.zeros([3072, 10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Define the classifier's result\n",
    "logits = tf.matmul(images_placeholder, weights) + biases\n",
    "\n",
    "# Define the loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "  labels=labels_placeholder))\n",
    "\n",
    "# Define the training operation\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Operation comparing prediction with true label\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), labels_placeholder)\n",
    "\n",
    "# Operation calculating the accuracy of our predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the TensorFlow graph\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Initialize variables\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  # Repeat max_steps times\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # Generate input data batch\n",
    "    indices = np.random.choice(data_sets['images_train'].shape[0], batch_size)\n",
    "    images_batch = data_sets['images_train'][indices]\n",
    "    labels_batch = data_sets['labels_train'][indices]\n",
    "\n",
    "    # Periodically print out the model's current accuracy\n",
    "    if i % 100 == 0:\n",
    "      train_accuracy = sess.run(accuracy, feed_dict={\n",
    "        images_placeholder: images_batch, labels_placeholder: labels_batch})\n",
    "      print('Step {:5d}: training accuracy {:g}'.format(i, train_accuracy))\n",
    "\n",
    "    # Perform a single training step\n",
    "    sess.run(train_step, feed_dict={images_placeholder: images_batch,\n",
    "      labels_placeholder: labels_batch})\n",
    "\n",
    "  # After finishing the training, evaluate on the test set\n",
    "  test_accuracy = sess.run(accuracy, feed_dict={\n",
    "    images_placeholder: data_sets['images_test'],\n",
    "    labels_placeholder: data_sets['labels_test']})\n",
    "  print('Test accuracy {:g}'.format(test_accuracy))\n",
    "\n",
    "endTime = time.time()\n",
    "print('Total time: {:5.2f}s'.format(endTime - beginTime))\n",
    "                                                                                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-37-9dfb2e984160>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-9dfb2e984160>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    print()\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "'''Restores a model from checkpoint and evaluates it on CIFAR-10'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "import data_helpers\n",
    "import two_layer_fc\n",
    "\n",
    "# Basic model parameters as external flags.\n",
    "flags = tf.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('hidden1', 120, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_string('train_dir', 'tf_logs',\n",
    "  'Directory to put the training data.')\n",
    "flags.DEFINE_float('reg_constant', 0.1, 'Regularization constant.')\n",
    "\n",
    "FLAGS._parse_flags()\n",
    "print('\\nParameters:')\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "print('{} = {}'.format(attr.upper(), value))\n",
    "print()\n",
    "\n",
    "IMAGE_PIXELS = 3072\n",
    "CLASSES = 10\n",
    "\n",
    "beginTime = time.time()\n",
    "\n",
    "data_sets = data_helpers.load_data()\n",
    "\n",
    "images_placeholder = tf.placeholder(tf.float32, shape=[None, IMAGE_PIXELS],\n",
    "  name='images')\n",
    "\n",
    "labels_placeholder = tf.placeholder(tf.int64, shape=[None], name='image-labels')\n",
    "\n",
    "logits = two_layer_fc.inference(images_placeholder, IMAGE_PIXELS,\n",
    "  FLAGS.hidden1, CLASSES, reg_constant=FLAGS.reg_constant)\n",
    "\n",
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "accuracy = two_layer_fc.evaluation(logits, labels_placeholder)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n",
    "  if ckpt and ckpt.model_checkpoint_path:\n",
    "    print('Restoring variables from checkpoint')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    current_step = tf.train.global_step(sess, global_step)\n",
    "    print('Current step: {}'.format(current_step))\n",
    "\n",
    "print('Test accuracy {:g}'.format(accuracy.eval(\n",
    "    feed_dict={ images_placeholder: data_sets['images_test'],\n",
    "                labels_placeholder: data_sets['labels_test']}\n",
    "  )))\n",
    "\n",
    "endTime = time.time()\n",
    "print('Total time: {:5.2f}s'.format(endTime - beginTime))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
